# 卒論

---


## はじめに

### 研究背景
### 本論文の構成
本論文の構成は、以下のとおりである。題2章では、関連研究として、畳み込みニューラルネットワークの特徴や、本研究で用いるVGGNetの構造について説明する。また、ドメイン適応およびデータ拡張に関する既存研究を整理し、特にニューラルスタイル転送をデータ拡張に応用した研究事例について述べる。題3章では、提案手法として、本研究での実験の構成と。題4章では、実験として、。題5章では、結論として、本研究の実験の結果から導かれる考察と今後の課題について述べる。

## 関連研究
本章では、提案手法で利用する畳み込みニューラルネットワークの概要とその特徴を示し、本研究で採用するVGGNetの構造と特徴について、説明する。さらに、本研究が取り組むドメイン適応とデータ拡張について、既存の研究を説明する。また、スタイル転送をデータ拡張に用いた事例を紹介する。

### 畳み込みニューラルネットワーク
畳み込みニューラルネットワーク(convolutional neural network, CNN)とは、畳み込みを用いているニューラルネットワークを指し、画像認識の分野で用いられている。CNNの特徴として、データの局所的なパターンを検出することができる。

以降では、畳み込み層(Convolutional Layer)、プーリング層(Pooling Layer)、活性化関数、全結合層(Fully Connected Layer)およびDropoutについて、それぞれの仕組みを、説明する。

#### 畳み込み層
畳み込み層(Convolutional Layer)は、入力画像の局所的な特徴を抽出するために、機能する。

フィルタ(あるいはカーネル)と呼ばれる小さな重み行列を、ストライドとよばれる移動幅に従って、位置を変えながら適用し、そのたびに、対応領域との積和演算を行う。この演算は、畳み込み演算と呼ばれる。

畳み込みを適用する際に、入力データの周囲に新たなピクセルを追加する、パディングという作業が行われる。パディングによって、フィルタが入力データの端まで適用できるようになる。パディングを行うことによって、出力の空間的なサイズが減少することを、抑制することができる。パディングのうち、周囲のデータをゼロで埋める手法は、ゼロパディングと呼ばれる。

#### プーリング層
プーリング層(Pooling Layer)は、畳み込み層において抽出された特徴マップを圧縮する層である。計算量を削減しつつ、位置ずれに対する頑健性を高める役割がある。特徴マップを小さな領域に分割し、各領域から代表値を出力することによって、重要な特徴を保ちながら情報を圧縮する。主なプーリング層の操作として、最大値プーリング(Max Poolig)や平均プーリング(Average Pooling)がある。最大値プーリングは、各領域の中で最も強く反応した値を選び出すため、特徴の存在そのものを強調する働きがある。平均プーリングは、値を均等に扱って平均を求める操作であり、領域全体の情報をなだらかにまとめるため、過度に尖った反応を抑えながら特徴を集約する傾向がある。

#### 活性化関数
活性化関数は、ニューラルネットワークの入力から、各ニューロンが受け取った入力信号をどのように出力するかを決定する役割を持つ。活性化関数を導入することによって、ネットワークは非線形な関係を学習することが可能となり、複雑なデータのパターンを表現できるようになる。非線形な活性化関数を用いない場合、ネットワーク全体は単純な線形変換の連続に過ぎず、層を重ねても表現力は線形モデルと同等にとどまる。そのため、複雑なパターンや特徴を捉えることができず、高度な分類や認識タスクにおいて十分な性能を発揮できない。

##### Relu
Reluは、活性化関数の1つである。ランプ関数とも呼ばれる。式は、Reluの関数を示している。xをReluへの入力、f(x)をReluの出力とする。Reluは、入力が0以下の場合は0を、0より大きい場合はそのままの値を出力する関数である。計算が単純であり、計算のコストが小さいという利点がある。入力が0であるとき、不連続となり、微分は定義できない。

図は、Reluの関数の形状を示している。x軸は関数への入力、y軸は関数の出力を示している。

##### Sigmoid
Sigmoidは、活性化関数の１つである。式は、Sigmoidの関数を示している。xをSigmoidへの入力、f(x)をSigmoidの出力とする。Sigmoidは、入力値を0から1の範囲にする関数である。この性質により、確率的な解釈が可能となる。入力値が大きい、または、小さい場合、勾配がほぼゼロになり、学習が進みにくくなる、という問題がある。この問題は、勾配消失問題として知られている。

図は、Sigmoidの関数の形状を示している。x軸は関数への入力、y軸は関数の出力を示している。

##### Softmax
Softmaxは、活性化関数の1つである。式は、Softmaxの関数を示している。xをSoftmaxへの入力、f(x)をSoftmaxの出力とする。多クラス分類の問題において用いられる活性化関数である。Softmaxは入力ベクトルを各クラスに対する確率として正規化する。出力は、0から1の間の値を取り、すべての出力の合計は1となる。Softmaxは、Sigmoidの多次元拡張であると言える。

図は、Softmaxの関数の形状を示している。x軸は関数への入力、y軸は関数の出力を示している。

#### 全結合層
全結合層(Fully Connected Layer)は、すべてのノードが接続している層である。受け取った特徴を組み合わせてより抽象的な概念を学習し、最終的な判断や出力を行う役割を持つ。畳み込み層などで抽出された特徴を最終的に分類するために、この全結合層が使われる。

#### Dropout
Dropoutは、正則化のための手法の1つである。Srivastavaらによって、2014年に提案された。正則化とは、モデルが訓練データに過度に適合する「過学習」を防ぎ、未知のデータに対する汎化能力を高めるための手法である。

Dropoutでは、学習の過程でネットワークから、ランダムに、ノードをその接続ごと取り除く。Dropoutは、隠れ層だけでなく入力層のノードにも適用されるが、出力層には適用されない。学習時には一部のノードが取り除かれるが、推論時には全てのノードを使用する。その際、出力を調整し学習時の挙動と整合性のあるようにする。

### VGGNet
VGGNetは、代表的な畳み込みニューラルネットワークの1つである。オックスフォード大学のVisual Geometry Groupによって、2014年に提案された。VGGNetは、16層(畳み込み層13層と全結合層3層)で構成されるVGG16と、19層(畳み込み層16層と全結合層3層)であるVGG19がある。VGGNetでは、3×3のフィルタを用いる畳み込み層を一貫して用い、層を深くすることによって、抽象的な特徴を捉えるようになることが、図られている。VGGが提案される以前に主流となっていたAlexnetでは、複数の複数の異なる大きさのフィルタを用いていた。

まず、VGG16について説明する。以下の図が、VGG16のアーキテクチャである。

まず、VGG19について説明する。以下の図が、VGG19のアーキテクチャである。

### スタイル転送技術
スタイル転送とは、スタイルを示している画像とコンテンツを示している画像の2枚から、コンテンツを維持したままスタイルをコンテンツ画像に適用した、新しい画像を生成する技術である。

#### ニューラルスタイル転送
ニューラルスタイル転送(Neural Style Transfer, NST)とは、畳み込みニューラルネットワークが内部で形成する特徴表現を用いて、コンテンツ画像がもつ情報とスタイル画像がもつ情報を同時に最適化することによって、新たな画像を生成する手法である。ニューラルスタイル転送には、記述的な手法と生成的な手法がある。記述的手法とは、ノイズ画像のピクセルを反復的に更新する手法を指し、生成的手法は、スタイルを事前学習されたモデルを用いて、1回の順伝播で行う手法を指す。

Leon A. Gatysらによって、ニューラルスタイル転送は2015年にはじめて提案された。その後、2016年に、査読付き会議で提案された。この手法は、記述的手法である。本研究では、この手法を用いる。また、その手法を、複数枚のスタイル画像を入力とできるように拡張した手法を用いる。手法の具体的な説明は、次の節で行う。


その後、一回の順伝播によってスタイル転送を行うことができる手法が提案された。この手法では、この手法では、一度生成用のネットワークを学習すると、記述的手法に比べて、画像の生成に要する時間が短い。図は、この手法のアーキテクチャを示している。


##### Leon A. Gatysによるニューラルスタイル転送の手法
以下の図は、Leon A. Gatysらによって提案されたニューラル転送のアーキテクチャを示している。

まずコンテンツ画像とスタイル画像を、それぞれ、事前学習された畳み込みニューラルネットワークに入力し、特徴マップを抽出する。これらの特徴は、層ごとに捉えている情報が異なる点に特徴があり、浅い層ではエッジや色のような低次特徴、深い層では物体の構造や形状のような高次特徴が得られる。この性質を利用することによって、コンテンツとスタイルの役割を明確に分担させることが可能となる。スタイルの特徴は、式のように、グラム行列を用いる。グラム行列を用いることによって、位置に依存せず、様々なスケールて情報を捉えることができる。

コンテンツの損失は式のように、スタイルの損失は式にように、それぞれ計算する。そして、式のように、損失を合計する。$`\alpha`$と$`\beta`$は、スタイルとコンテンツの重みを表す。

初期画像から、損失が小さくなるように、勾配の計算をする。そして、画像を更新する。

### ドメイン適応
学習時のデータと推論時のデータのドメインが異なる際に、一般に、推論の精度が低下することが知られている。ドメインとは、データの特性が異なる環境や条件を指す。特に、本研究でのドメインとは、画像の種類、例えば自然画像、手書きのイラスト、などのように、異なるカテゴリに分類される画像を指す。ドメイン適応とは、ドメインが異なる際に、精度を向上させる問題のことを指す。

まず、ドメイン適応の種類の1つとして、

### データ拡張
データ拡張とは、訓練データが少ない際に、データを増やすことによって、モデルの精度を向上することをすることを目指す手法のことである。ここでは、データ拡張の手法は、幾何学変換と測光変換の2つのカテゴリーの分類される。幾何学変換とは、サイズの変更や回転など、元の画像の形状を変更する手法を指す。一方、測光変換とは、彩度の調整やグレースケール処理など、画像のRGBを変更する手法を指す。更に、近年では、生成的な手法によって画像を増やす手法も提案されている。

データ拡張の問題点として、不適切な方法で行うと、モデルの精度が低下してしまう、という点がある。例えば、自動車のデータセットに対して上下を反転することによるデータ拡張を行うと、実際の走行環境ではほとんど観測されない「逆さまの自動車」という不自然なデータが学習に含まれてしまい、モデルが本来学習すべき特徴と無関係なパターンを覚えてしまう可能性がある。その結果、現実の画像に対する識別性能が低下してしまう。

### ニューラルスタイル転送を用いたデータ拡張による精度向上
先行研究として、ニューラルスタイル転送を用いてデータ拡張を行い、モデルの精度向上を図った、STaDA(Style Transfer as Data Augmentation)という研究がある。この研究では、1回の順伝播で画像を作成することができる、生成型のスタイル転送を用いている。

この研究では、以下に示している７枚の写真を、スタイル画像として、利用している。もとのデータセットに対して、スタイル画像を用いた画像生成を行うことによって、データセットの画像数をに2倍に拡張している。画像は、101個のクラスで構成されている、Caltech 101というラベル付き画像データセットを用いている。

この研究では、スタイル画像のうち、Snowを用いたスタイル転送によって生成した画像を用いることによって、精度が向上することが示された。しかし、Your nameなど、一部のスタイル画像における例では、精度の低下が示された。スタイル画像によって、精度が向上する場合と低下する場合があることが、この研究の結果からわかる。

また、この研究では、伝統的なデータ拡張手法として、FlippingとRotationを使用した実験も行っている。Flippingとは、左右を反転させた画像を生成する操作である。Rotationとは、上下を反転させた画像を生成する操作である。この研究では、Flipping単体では精度は低下するが、WaveとFlippingを組み合わせた手法では精度が向上している。データ拡張手法の組み合わせ方によって、精度に違いがあることが、この研究の結果からわかる。

## 提案手法

### 基本方針
本研究では、ニューラルスタイル転送を用いて、スタイル画像のドメインの画像を生成する。そして、生成した画像を用いて、画像分類の畳み込みニューラルネットワーク
### データ拡張手法
### 提案手法から期待する効果

## 実験
### 実験の目的

### データセット
本研究では、ドメイン適応の精度を評価するために、4つのドメインで構成されている、PACSデータセットを用いる。Photoのドメインの画像は多くあり、それ以外のドメインの画像は少数のみある、という状況における課題を、今回の研究では扱う。

また、VGGNetの事前学習を行うためにImageNetを用いる。

### 実験環境
実験環境として、GPUを搭載している計算機を用いる。図は、実験で実際に用いる計算機のGPU、CPU、メモリ、OSを表す。GPUは、並列の数値計算を高速に行うことができる。ディープラーニングでは並列の計算を多く行うため、GPUを用いることによって、高速化を達成することができる。

ニューラルスタイル転送と画像分類のCNNは、Pythonを用いた。また、ニューラルネットワークの構築と学習用のライブラリとして、TensorflowとKerasを用いて実装を行った。Pythonはバージョン3.12.2、Tensorflowはバージョン2.18.1、Kerasはバージョン3.6.0を用いた。

また、ニューラルスタイル転送と画像分類のCNNにおいて、事前にImagenetを用いて事前学習を行っているVGGNetの重みは、Kerasによって提供されているものを用いる。入手は、VGG16およびVGG19において、以下のコードを用いてそれぞれ行った。

VGG16
```
import keras
model = keras.applications.VGG16(
    weights="imagenet",
    include_top=False,
)
```

VGG19
```
import keras
model = keras.applications.VGG19(
    weights="imagenet",
    include_top=False,
)
```


本研究で画像分類を行うCNNは、VGG16を基盤とし、、ImageNetで事前学習された重みを用いた畳み込み層部分を特徴抽出器として利用し、そのパラメータを固定した上で、新たに全結合層および分類層を付加したものとする。以下の図は実際のネットワークの構成を示す。

#### PACSデータセット
PACSは、Photo Art Cartoon Sketchの略であり、4つのドメインで構成されている、ラベル付き画像データセットである。Photoは1670枚、Artは2048枚、Cartoonは2344枚、Sketchは3929枚で構成されている。各ドメインは、dog、elephant、giraffe、guitar、horse、house、personの、7つのクラスがある。本研究では、各ドメインの画像を三対一の割合で分割し、それぞれを学習用と評価用として利用する。

図は、各ドメインの、クラス毎の画像の例である。

表は、各ドメインの、クラス毎の画像の数を示している。

#### ImageNet
ImageNetは、Fei-Fei Liらによって2009年に発表されたラベル付き画像データセットである。1000クラスで構成され、100万枚を超える様々な画像が含まれている。ImageNetによる学習によって獲得する特徴表現は、画像を入力とする多様なタスクに対して、普遍的に有効であることがわかっているので、転移学習に活用されている。

図は、ImageNetに含まれている画像データの例である。

### 実験1: ベースとなるクラス分類の精度と、画像生成に要する時間の測定 
#### 目的
#### 方法
#### 結果
#### 考察
### 実験2: 
#### 目的
#### 方法
#### 結果
#### 考察
### 実験3: 
#### 目的
#### 方法
#### 結果
#### 考察
### 実験4: 
#### 目的
#### 方法
#### 結果
#### 考察

## 結論
### 提案手法による成果
### 今後の課題
今後の課題として、まず、画像のクラス分類以外のタスクにおける精度の変化を調べる必要があると、考える。例えば、画像のピクセルに対してラベル付けを行うセマンティックセグメンテーションや、物体の位置と範囲を推論する物体検出が挙げられる。また、

---
---


# メモ

- https://www.ite.or.jp/contents/keywords/2303keyword.pdf
- https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf
- https://keras.io/api/applications/vgg/
- https://www.ibm.com/jp-ja/think/topics/data-augmentation
- https://www.jstage.jst.go.jp/article/iieej/37/6/37_6_815/_pdf/-char/ja

